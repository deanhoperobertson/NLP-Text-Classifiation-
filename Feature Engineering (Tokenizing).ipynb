{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Text Classification 1.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "T6WVgphTn67y",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Amazon Reviews "
      ]
    },
    {
      "metadata": {
        "id": "w3w5vvVYn4yQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import urllib.request\n",
        "import pandas as pd\n",
        "import urllib\n",
        "from sklearn import model_selection, preprocessing\n",
        "\n",
        "#Feature Engineering\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.feature_selection import SelectKBest\n",
        "from sklearn.feature_selection import f_classif\n",
        "\n",
        "#keras\n",
        "from keras.preprocessing.text import Tokenizer\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "78pugyJOynLK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#import data from my github repo\n",
        "url = \"https://raw.githubusercontent.com/deanhoperobertson/NLP-Text-Classifiation-/master/corpus.txt\"\n",
        "data = urllib.request.urlopen(url).read()\n",
        "data = data.decode('utf-8')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7PAkE3eNzVqy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "labels, texts = [], []\n",
        "for i, line in enumerate(str(data).split(\"\\n\")):\n",
        "    content = line.replace(\"\\\\\",\"\").split()\n",
        "    labels.append(content[0])\n",
        "    texts.append(\" \".join(content[1:]))\n",
        "\n",
        "# create a dataframe using texts and lables\n",
        "trainDF = pd.DataFrame()\n",
        "trainDF['text'] = texts\n",
        "trainDF['label'] = labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "h5gcD26U0fhV",
        "colab_type": "code",
        "outputId": "0325874c-e51c-4c1e-ca0e-86e3c5d5dd63",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "cell_type": "code",
      "source": [
        "trainDF.head()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Stuning even for the non-gamer: This sound tra...</td>\n",
              "      <td>__label__2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>The best soundtrack ever to anything.: I'm rea...</td>\n",
              "      <td>__label__2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Amazing!: This soundtrack is my favorite music...</td>\n",
              "      <td>__label__2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Excellent Soundtrack: I truly like this soundt...</td>\n",
              "      <td>__label__2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Remember, Pull Your Jaw Off The Floor After He...</td>\n",
              "      <td>__label__2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text       label\n",
              "0  Stuning even for the non-gamer: This sound tra...  __label__2\n",
              "1  The best soundtrack ever to anything.: I'm rea...  __label__2\n",
              "2  Amazing!: This soundtrack is my favorite music...  __label__2\n",
              "3  Excellent Soundtrack: I truly like this soundt...  __label__2\n",
              "4  Remember, Pull Your Jaw Off The Floor After He...  __label__2"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "metadata": {
        "id": "5h20wHW3Rap5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#split into train and test set (default is 25%)\n",
        "#set seed for consistency\n",
        "train_x, valid_x, train_y, valid_y = model_selection.train_test_split(trainDF['text'], trainDF['label'], test_size=0.25, random_state=1)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gq9BOx5llPh3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# encode target labels into intergers between 0 - no.classes\n",
        "# label 2 = 1\n",
        "# label 1 = 0\n",
        "encoder = preprocessing.LabelEncoder()\n",
        "train_y = encoder.fit_transform(train_y)\n",
        "valid_y = encoder.fit_transform(valid_y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QVADyn6ioWXk",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Feature Engineeering"
      ]
    },
    {
      "metadata": {
        "id": "-uPKO9PKt_sH",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Now we need to convert the worded sentences into vectors by replacing the words with numercil representation. \n",
        "\n",
        "for Example:\n",
        "\"The cat sat on the hat\" = {1,3,10,7,1,12}\n",
        "\n",
        "This can be done in a number of ways such as:\n",
        "-  CountVectorizer (Bag of Words)\n",
        "- TF-IDF Matrix\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "zbk8yG5Gz4gj",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 1.1 Bag of Words\n",
        "\n",
        "Here we use countervectorize to create a \"bag of words\", that is a corpus of unique words from the text that we are interested in modeling. The CountVectorizer's defaults settings:\n",
        "- Convert all characters into lower case\n",
        "- Remove all stops words such as “the”, “a”, “an”, “in” \n",
        "\n",
        "This bag of words is then used to vectorize each sentence (row) is a document term matrix with the columns defined a specific term/word.\n",
        "\n",
        "- fit() function - learns a vocabulary from text\n",
        "- transform() function - encodes the documents into vectors \n",
        "\n",
        "\n",
        "**Pro's**\n",
        "- Easy to undertand and apply\n",
        "- Flexible vocabulary\n",
        "\n",
        "**Cons**\n",
        "- All words are treated eqaully (include meanlingless words)\n",
        "-  Discarding word order ignores the context, which can be very valuable in text model. \n"
      ]
    },
    {
      "metadata": {
        "id": "u5ulHOXYNowx",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "![alt text](Bag of Words.png \"Title\")"
      ]
    },
    {
      "metadata": {
        "id": "SP9pV3kvKnZC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 1.1.1 CountVectorizer"
      ]
    },
    {
      "metadata": {
        "id": "Uq1xfy220Amj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# instantiate a count vectorizer object to tokenize on a word level\n",
        "count_vect = CountVectorizer(analyzer='word', token_pattern=r'\\w{1,}', strip_accents =\"ascii\", stop_words=None)\n",
        "count_vect.fit(trainDF['text'])\n",
        "\n",
        "#see the unique words being tokenized \n",
        "count_vect.get_feature_names()[1:10]\n",
        "\n",
        "#create a document term matrix using the \n",
        "xtrain_count =  count_vect.transform(train_x)\n",
        "xvalid_count =  count_vect.transform(valid_x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jlS1EQ4CPUts",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Here we can see the how the each word have been tokenized\n",
        "# count_vect.vocabulary_"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "phXw5jva5QWx",
        "colab_type": "code",
        "outputId": "9c1c7b4a-7183-4daa-9f99-e1ad791990b0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        }
      },
      "cell_type": "code",
      "source": [
        "#view that DT matrix in dataframe\n",
        "pd.DataFrame(xtrain_count.toarray(), columns=count_vect.get_feature_names()).head()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>00</th>\n",
              "      <th>000</th>\n",
              "      <th>001</th>\n",
              "      <th>002</th>\n",
              "      <th>00290</th>\n",
              "      <th>007</th>\n",
              "      <th>0070412901</th>\n",
              "      <th>0072316373</th>\n",
              "      <th>008</th>\n",
              "      <th>...</th>\n",
              "      <th>zzzz</th>\n",
              "      <th>zzzzz</th>\n",
              "      <th>zzzzzz</th>\n",
              "      <th>zzzzzzz</th>\n",
              "      <th>zzzzzzzzzz</th>\n",
              "      <th>zzzzzzzzzzzz</th>\n",
              "      <th>zzzzzzzzzzzzz</th>\n",
              "      <th>zzzzzzzzzzzzzzzzzz</th>\n",
              "      <th>zzzzzzzzzzzzzzzzzzzzz</th>\n",
              "      <th>zzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzz</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 31635 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   0  00  000  001  002  00290  007  0070412901  0072316373  008  \\\n",
              "0  0   0    0    0    0      0    0           0           0    0   \n",
              "1  0   0    0    0    0      0    0           0           0    0   \n",
              "2  0   0    0    0    0      0    0           0           0    0   \n",
              "3  0   0    0    0    0      0    0           0           0    0   \n",
              "4  0   0    0    0    0      0    0           0           0    0   \n",
              "\n",
              "                                       ...                                       \\\n",
              "0                                      ...                                        \n",
              "1                                      ...                                        \n",
              "2                                      ...                                        \n",
              "3                                      ...                                        \n",
              "4                                      ...                                        \n",
              "\n",
              "   zzzz  zzzzz  zzzzzz  zzzzzzz  zzzzzzzzzz  zzzzzzzzzzzz  zzzzzzzzzzzzz  \\\n",
              "0     0      0       0        0           0             0              0   \n",
              "1     0      0       0        0           0             0              0   \n",
              "2     0      0       0        0           0             0              0   \n",
              "3     0      0       0        0           0             0              0   \n",
              "4     0      0       0        0           0             0              0   \n",
              "\n",
              "   zzzzzzzzzzzzzzzzzz  zzzzzzzzzzzzzzzzzzzzz  \\\n",
              "0                   0                      0   \n",
              "1                   0                      0   \n",
              "2                   0                      0   \n",
              "3                   0                      0   \n",
              "4                   0                      0   \n",
              "\n",
              "   zzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzz  \n",
              "0                                                  0                             \n",
              "1                                                  0                             \n",
              "2                                                  0                             \n",
              "3                                                  0                             \n",
              "4                                                  0                             \n",
              "\n",
              "[5 rows x 31635 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "metadata": {
        "id": "OEABLErd7jr1",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 1.1.2 Bag of Words ( with Keras)"
      ]
    },
    {
      "metadata": {
        "id": "-yuVzP7l8L7W",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#tokenizes the words - here we aree able to define the maxium number of words we would like to include ranked by frequency\n",
        "t = Tokenizer(num_words=None)\n",
        "# fit the tokenizer on the documents\n",
        "t.fit_on_texts(trainDF['text'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TCDtg-AzImvn",
        "colab_type": "code",
        "outputId": "fb006c2f-451b-4220-bf33-64e90c2dc726",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "#see vectorization of words\n",
        "type(t.word_counts)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "collections.OrderedDict"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "metadata": {
        "id": "0LrUT1OTIyWD",
        "colab_type": "code",
        "outputId": "0b9309f0-eb92-4d6b-9d0f-b145daa6f7d4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "cell_type": "code",
      "source": [
        "xtrain_keras = t.texts_to_matrix(train_x, mode='count')\n",
        "xvalid_keras = t.texts_to_matrix(valid_x, mode='count')\n",
        "print(xtrain_keras)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 0. 11.  1. ...  0.  0.  0.]\n",
            " [ 0.  1.  1. ...  0.  0.  0.]\n",
            " [ 0.  3.  0. ...  0.  0.  0.]\n",
            " ...\n",
            " [ 0.  3.  1. ...  0.  0.  0.]\n",
            " [ 0.  2.  1. ...  0.  0.  0.]\n",
            " [ 0.  6.  3. ...  0.  0.  0.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "SrC-gyCG-1mr",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##1.2 TD-IDF Vectors \n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "nGQW0mmcIXTQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "A TDIF matrix is an alternative method of representing  words in tokenized form. This method differs from the traditional bag of words model as it weights the importance of each word different depending on its frequency within the list of documents. \n",
        "\n",
        "This allows for words like “the” which generally appear many times (large counts) and are not very meaningful in the encoded vectors. The TD-IFD vectorization method weights these meaningless words less than other words that offer more value. TF-IDF score is composed by two terms:\n",
        "\n",
        "- Normalized Term Frequency (TF)\n",
        "- Inverse Document Frequency (IDF)\n",
        "\n",
        "with the following formula:\n",
        "\n",
        "\\begin{align}\n",
        "\\frac{Term Frequency​(TF)}{Inverse Document Frequency​(IDF)}\n",
        "\\end{align}\n",
        "\n",
        "TF component summarizes how often a given word appears within a document, and the IDF component reduces the weighting of words that appear a lot across documents. This is done using by computing  logarithm (Ln) of the number of the documents in the corpus divided by the number of documents where the specific term appears.\n",
        "\n",
        "The end result is method of vectorizing text that **highlights** words that are more interesting within a collections of texts. \n",
        "\n",
        "**Pros**\n",
        "- Accounts for different word importance\n",
        "- small range of values in matrix speeds up convergance\n",
        "\n",
        "**Cons**\n",
        "- Discards word order ignores and thus looses context.\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "-AZU8sPWwQLZ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 1.2.1 Word-Level"
      ]
    },
    {
      "metadata": {
        "id": "TMviocS9PFYF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# vectorizing on a word level\n",
        "tfidf_vect = TfidfVectorizer(analyzer='word', token_pattern=r'\\w{1,}', max_features=5000)\n",
        "tfidf_vect.fit(trainDF['text'])\n",
        "xtrain_tfidf =  tfidf_vect.transform(train_x)\n",
        "xvalid_tfidf =  tfidf_vect.transform(valid_x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jM6zZtO8TIv6",
        "colab_type": "code",
        "outputId": "830a30f4-fbb2-449a-8f79-334e11144de1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "# The first line shows the vectoriztion of vocab\n",
        "# The idf score indicates how frequent the word is. The lowest score of 1.0 to the most frequently observed word\n",
        "type(tfidf_vect.vocabulary_)\n",
        "print(tfidf_vect.idf_[1:10])"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[6.62692143 6.54687872 4.07921388 4.6731061  5.47424192 7.57138304\n",
            " 6.40377788 5.81599121 7.72553372]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ijNupMTMweks",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 1.2.2 N-gram Level (Basic)\n",
        "\n",
        "A further level of vectorization is adapting an N-gram approach which processes text as a sequence of words. Simply put, an N-gram is a sequence of N words. N-grams can be any size greater than one word. For Example:\n",
        "\n",
        "\"Doctor\" - Uni-gram <br>\n",
        "\"Doctor has\" = Bi-gram\" <br>\n",
        "\"Doctor has evidence\" - Tri-gram <br>\n",
        "\n",
        "The N-gram approach cater for the fact that some words are often found in close proximitry to each other and together can have a very different meaning processed individually. For example, the bi-gram \"not good\" has a very different meaning if processed as \"not\" & \"good\" on a word level. The N-gram model allows for these words relationships to be reckonized within the text. \n",
        "\n",
        "In most cases, we set an N-gram range that allow a variety of sized N-grams a chance to be presented. \n"
      ]
    },
    {
      "metadata": {
        "id": "yBcYDhFH6TOM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# ngram level tf-idf \n",
        "tfidf_vect_ngram = TfidfVectorizer(analyzer='word', token_pattern=r'\\w{1,}', ngram_range=(2,3), max_features=5000)\n",
        "tfidf_vect_ngram.fit(trainDF['text'])\n",
        "xtrain_tfidf_ngram =  tfidf_vect_ngram.transform(train_x)\n",
        "xvalid_tfidf_ngram =  tfidf_vect_ngram.transform(valid_x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4zSmD7LZc_8l",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##1.3 Customize a Vectorization Function"
      ]
    },
    {
      "metadata": {
        "id": "zc1fKkx5dEE_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#only take the top 2000 N-grams and \n",
        "#ignore words that a doc freq of less than 2 \n",
        "TOP_K = 20000\n",
        "MIN_DOC_FREQ = 2\n",
        "\n",
        "def ngram_vectorize(train_texts, train_labels, val_texts):\n",
        "    kwargs = {\n",
        "        'ngram_range' : (1, 2),\n",
        "        'dtype' : 'int32',\n",
        "        'strip_accents' : 'unicode',\n",
        "        'decode_error' : 'replace',\n",
        "        'analyzer' : 'word',\n",
        "        'min_df' : MIN_DOC_FREQ,\n",
        "    }\n",
        "    \n",
        "    # Learn Vocab from train texts and vectorize train and val sets\n",
        "    tfidf_vectorizer = TfidfVectorizer(**kwargs)\n",
        "    x_train = tfidf_vectorizer.fit_transform(train_texts)\n",
        "    x_val = tfidf_vectorizer.transform(val_texts)\n",
        "    \n",
        "    # Select best k features, with feature importance measured by f_classif (which is the deafault)\n",
        "    selector = SelectKBest(f_classif, k=min(TOP_K, x_train.shape[1]))  \n",
        "    selector.fit(x_train, train_labels)\n",
        "    x_train = selector.transform(x_train).astype('float32')\n",
        "    x_val = selector.transform(x_val).astype('float32')\n",
        "    return x_train, x_val"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7nE0QIxPf7vk",
        "colab_type": "code",
        "outputId": "5e5dd814-0c4f-49fa-c324-9db92c3ff8fa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "cell_type": "code",
      "source": [
        "    # Vectorize the data and returns a tf-idf matrix\n",
        "    x_train, x_val = ngram_vectorize(train_x, train_y, valid_x)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/feature_extraction/text.py:1569: UserWarning: Only (<class 'numpy.float64'>, <class 'numpy.float32'>, <class 'numpy.float16'>) 'dtype' should be used. int32 'dtype' will be converted to np.float64.\n",
            "  UserWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}